{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPF+sB95VLlx9Y6wVr2dgbf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/callmemark/Correlation-of-Night-Air-Temperature-and-light-pollution-in-major-cities-in-the-Philippines/blob/main/Thesis_Proc.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1> Correlation of Night Air Temperature and light pollution in major cities in the Philippines </h1>\n",
        "\n",
        "\n",
        "---\n",
        "</br></br>\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "> Fernandez, Jaron Rix\n",
        "</br>\n",
        "Velmonte, Mark john A.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "RABrvrp2qX4p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1>Preperation 1: Install Libraries</h1>\n",
        "\n",
        "> Install neccesary libraries"
      ],
      "metadata": {
        "id": "Sy9S6BtAqfyX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install GDAL and Geopandas\n",
        "!apt install gdal-bin python-gdal python3-gdal --quiet\n",
        "!apt install python3-rtree --quiet\n",
        "!pip install --upgrade pip --quiet\n",
        "!pip install git+git://github.com/geopandas/geopandas.git --quiet\n",
        "!pip install descartes --quiet\n",
        "!pip install ipywidgets --quiet\n",
        "\n",
        "# Install other libraries\n",
        "!pip install splot --quiet\n",
        "!pip install -U mgwr --quiet\n",
        "\n",
        "#!pip freeze"
      ],
      "metadata": {
        "id": "LdXV1hAsnuyB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1>Preperation 2: Import Libraries</h1>\n",
        "\n",
        "> after installation we procced to import the libraries"
      ],
      "metadata": {
        "id": "YJrBnv2Zqszf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "9oawj62ciWQo"
      },
      "outputs": [],
      "source": [
        "#import libraries\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import geopandas as gpd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib as mpl\n",
        "import libpysal as ps\n",
        "from mgwr.gwr import GWR, MGWR\n",
        "from mgwr.sel_bw import Sel_BW\n",
        "from mgwr.utils import shift_colormap, truncate_colormap\n",
        "from google.colab import drive\n",
        "from os import path, getcwd\n",
        "import itertools\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn import linear_model\n",
        "import statsmodels.api as sm"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1> Preperation 3: Moun Drive </h1>\n",
        "\n",
        "> To access data from google drive, We need to give permission to mount the drive and gain access to folders and files"
      ],
      "metadata": {
        "id": "XiqsCfH7q9Bn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#mount the google drive used\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "2DUnJhipl4Jq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "98116f89-74e2-4a5c-be81-68f30072ce07"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1>Preperation 4: File Reference </h1>\n",
        "\n",
        "> Create a dictionary to use for file path reference and for process automation"
      ],
      "metadata": {
        "id": "_IWQb6eara_5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "GPKG_DATASET_DIRECTORY = \"/content/drive/My Drive/COLLEGE_THESIS_FOLDER/GPKG_FILES/\"\n",
        "\n",
        "\n",
        "gpkg_files_dict = {\n",
        "    \"Manila_City\" : \"Manila_City.gpkg\",\n",
        "    \"Taguig_City\" : \"Taguig_City.gpkg\",\n",
        "    \"Pasig_City\" : \"Pasig_City.gpkg\",\n",
        "    \"Paranaque_City\" : \"Paranaque_City.gpkg\",\n",
        "    \"Makati_City\" : \"Makati_City.gpkg\",\n",
        "    \"LasPinas_City\" : \"LasPinas_City.gpkg\",\n",
        "    \"Muntinlupa_City\" : \"Muntinlupa_City.gpkg\",\n",
        "    \"Pasay_City\" : \"Pasay_City.gpkg\",\n",
        "    \"Malabon_City\" : \"Malabon_City.gpkg\",\n",
        "    \"Butuan_City\" : \"Butuan_City.gpkg\",\n",
        "    \"grouped_study_area\" : \"grouped_study_area.gpkg\"  \n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "DATASET_DIRECTORY = \"/content/drive/My Drive/COLLEGE_THESIS_FOLDER/DataSet/climactic_factor_dataset_v2/\"\n",
        "\n",
        "CITY_NAME= [\n",
        "    \"manila_city\",\n",
        "    \"valenzuela_city\",\n",
        "    \"taguig_city\",\n",
        "    \"pasig_city\",\n",
        "    \"pasay_city\",\n",
        "    \"paranaque_city\",\n",
        "    \"muntinlupa_city\",\n",
        "    \"malabon_city\",\n",
        "    \"makati_city\",\n",
        "    \"laspinas_city\"\n",
        "]\n",
        "\n",
        "\n",
        "LIGHTPOL_DIRECTORY = \"/content/drive/My Drive/COLLEGE_THESIS_FOLDER/DataSet/Light_pol_data/\"\n",
        "\n",
        "y_ext = [\"2012\", \"2013\", \"2014\", \"2015\", \"2016\", \"2017\", \"2018\", \"2019\", \"2020\", \"2021\"]\n",
        "lpol_cname = [\n",
        "  \"manila_lpol_data_\",\n",
        "  \"taguig_lpol_data_\",\n",
        "  \"pasig_lpol_data_\",\n",
        "  \"paranaque_lpol_data_\",\n",
        "  \"makati_lpol_data_\",\n",
        "  \"laspinas_lpol_data_\",\n",
        "  \"muntinlupa_lpol_data_\",\n",
        "  \"pasay_lpol_data_\",\n",
        "  \"malabon_lpol_data_\",\n",
        "  \"valenzuela_lpol_data_\",\n",
        "]"
      ],
      "metadata": {
        "id": "cyo_qF39lvu_"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1>Preperation 5: Create helper function and class</h1>\n",
        "\n",
        "> Create function and classes methods that will be use repeatedly"
      ],
      "metadata": {
        "id": "2AbD9A_aZgRQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Helper functions and Classes\n",
        "def get_gpk_fpath(city_name_arg = str):\n",
        "  try:\n",
        "    return GPKG_DATASET_DIRECTORY + gpkg_files_dict[city_name_arg]\n",
        "  except:\n",
        "    raise Exception(\"error in get_gpk_fpath func | No City in dataset\")\n",
        "    \n",
        "\n",
        "def get_file_path(city_name_arg):\n",
        "  _fstr = DATASET_DIRECTORY + city_name_arg + \".csv\"\n",
        "  return _fstr\n"
      ],
      "metadata": {
        "id": "Bg4kUtWzpXys"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MMREG_PROCS():\n",
        "  def __init__(self, x_arg, y_arg):\n",
        "    self.x_sample = x_arg\n",
        "    self.y_sample = y_arg\n",
        "\n",
        "\n",
        "  def check_linearity_by_mapping(self, x_axis_arg, y_axis_arg):\n",
        "    plt.scatter(df['interest_rate'], df['index_price'], color='red')\n",
        "    plt.title('Index Price Vs Interest Rate', fontsize=14)\n",
        "    plt.xlabel('Interest Rate', fontsize=14)\n",
        "    plt.ylabel('Index Price', fontsize=14)\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "  \n",
        "\n",
        "  def standard_proc(self, _show_plot_arg = True):\n",
        "    self.scikit_train_proc(show_plot_arg = _show_plot_arg)\n",
        "    self.statmod_proc()\n",
        "\n",
        "\n",
        "  def scikit_train_proc(self, test_size_arg = 0.3, random_state_arg = 0, show_plot_arg = True):\n",
        "    self.lr_model = LinearRegression()\n",
        "    self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(self.x_sample, self.y_sample, test_size = test_size_arg, random_state = random_state_arg)\n",
        "    self.lr_model.fit(self.X_train, self.y_train)\n",
        "    self.y_pred_train = self.lr_model.predict(self.X_train)\n",
        "\n",
        "    if show_plot_arg:\n",
        "      plt.scatter(self.y_train, self.y_pred_train)\n",
        "      plt.show()\n",
        "\n",
        "    return [self.y_train, self.y_pred_train]\n",
        "\n",
        "\n",
        "  def scikit_proc(self):\n",
        "    regr = linear_model.LinearRegression()\n",
        "    fitted_model = regr.fit(x, y)\n",
        "\n",
        "    print(\"Intercept: \", fitted_model.intercept_)\n",
        "    print('Coefficients: ', fitted_model.coef_)\n",
        "\n",
        "    return fitted_model\n",
        "\n",
        "\n",
        "  def statmod_proc(self):\n",
        "    _x = sm.add_constant(self.x_sample)\n",
        " \n",
        "    model = sm.OLS(self.y_sample, _x).fit()\n",
        "    predictions = model.predict(_x) \n",
        "    \n",
        "    reg_ressult = model.summary()\n",
        "    print(reg_ressult)\n",
        "\n",
        "    return reg_ressult"
      ],
      "metadata": {
        "id": "E15rZqedKmMD"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1>Procedures</h1>\n",
        "\n",
        "> 1. get light pollution annual average per city\n",
        "<br>\n",
        "> 2. filter data to obtains night time information (7pm-4am)\n",
        "<br>\n",
        "> 3. Calculate the annaul average of every parameter for every city"
      ],
      "metadata": {
        "id": "pbPtMz0BZ7qN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dict_keys = ['Manila_City', 'Taguig_City', 'Pasig_City', 'Paranaque_City', 'Makati_City', 'Las Pinas_City', 'Muntinlupa_City', 'Pasay_City', 'Malabon_City', 'Valenzuela_City']\n",
        "lpol_data_dict = {}\n",
        "\n",
        "for _index in range(len(lpol_cname)):\n",
        "  _avg_init_list = []\n",
        "  for _year in y_ext:\n",
        "    fname = lpol_cname[_index] + _year\n",
        "\n",
        "    avg_val = np.average(np.array(pd.read_csv(LIGHTPOL_DIRECTORY + fname + \".csv\", skiprows = 1))) # open csv || skip headder >> convert to numpy >> get avg\n",
        "    _avg_init_list.append(avg_val)\n",
        "\n",
        "  lpol_data_dict[dict_keys[_index]] = _avg_init_list\n",
        "  print(dict_keys[_index], \": Data Process complete\")\n",
        "\n",
        "lpol_data_df = pd.DataFrame(lpol_data_dict)"
      ],
      "metadata": {
        "id": "u_piBR72dTBA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc35491d-d753-476b-aa7f-c29bd13c524b"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Manila_City : Data Process complete\n",
            "Taguig_City : Data Process complete\n",
            "Pasig_City : Data Process complete\n",
            "Paranaque_City : Data Process complete\n",
            "Makati_City : Data Process complete\n",
            "Las Pinas_City : Data Process complete\n",
            "Muntinlupa_City : Data Process complete\n",
            "Pasay_City : Data Process complete\n",
            "Malabon_City : Data Process complete\n",
            "Valenzuela_City : Data Process complete\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create a empty dictionary\n",
        "nt_city_df_dict = {}\n",
        "\n",
        "# loop through the list\n",
        "for city in CITY_NAME:\n",
        "  dict_key = city\n",
        "  city_df = pd.read_csv(get_file_path(city), skiprows = 13)\n",
        "  \n",
        "  # filter data from t-19 to t-04\n",
        "  print(\"Proc city: \", city)\n",
        "  nightime_data = city_df.loc[(city_df[\"HR\"] <= 4) | (city_df[\"HR\"] >= 19)]\n",
        "\n",
        "  # create new dictinary item and add new data\n",
        "  nt_city_df_dict[dict_key] = nightime_data\n",
        "\n",
        "\n",
        "print(nt_city_df_dict.keys())"
      ],
      "metadata": {
        "id": "Pu1kWyc6pas5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78d5807a-4fde-4e20-bb97-46020051c1c6"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Proc city:  manila_city\n",
            "Proc city:  valenzuela_city\n",
            "Proc city:  taguig_city\n",
            "Proc city:  pasig_city\n",
            "Proc city:  pasay_city\n",
            "Proc city:  paranaque_city\n",
            "Proc city:  muntinlupa_city\n",
            "Proc city:  malabon_city\n",
            "Proc city:  makati_city\n",
            "Proc city:  laspinas_city\n",
            "dict_keys(['manila_city', 'valenzuela_city', 'taguig_city', 'pasig_city', 'pasay_city', 'paranaque_city', 'muntinlupa_city', 'malabon_city', 'makati_city', 'laspinas_city'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# year 2011-2020\n",
        "year_range = [i for i in range(2012, 2022)]\n",
        "# climactic factors\n",
        "df_params = [\"PS\", \"T2M\", \"QV2M\", \"WS10M\", \"PRECTOTCORR\", \"Lat\", \"Long\"]\n",
        "\n",
        "# initialize empty dictionary\n",
        "cities_yparam_avg_val = {}\n",
        "\n",
        "# loop through the cities \n",
        "for city_name in CITY_NAME: # or CITY_NAME_2010_2010 || Same value\n",
        "  city_dict_key = city_name\n",
        "  cities_yparam_avg_val[city_dict_key] = {}\n",
        "  \n",
        "  # loop through the climatic factors\n",
        "  for param_name in df_params:\n",
        "    # initialize new empty list every iteration\n",
        "    initial_param_avg_list = []\n",
        "\n",
        "    # loop through the year\n",
        "    for _year in year_range:\n",
        "      # get the average value of the current iterated climatic factor\n",
        "\n",
        "      tgt_y = nt_city_df_dict[city_dict_key].loc[nt_city_df_dict[city_dict_key][\"YEAR\"] == _year][param_name]\n",
        "      param_avg_val = np.average(np.array(tgt_y))\n",
        "\n",
        "      # appent to empty list\n",
        "      initial_param_avg_list.append(param_avg_val)\n",
        "\n",
        "      # add new dictionary key and its value\n",
        "      cities_yparam_avg_val[city_dict_key][param_name] = np.array(initial_param_avg_list)\n",
        "\n",
        "\n",
        "print(cities_yparam_avg_val.keys())"
      ],
      "metadata": {
        "id": "sSrV2XzfpdVG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d4187ce-f1b4-4463-982a-a0f2571d430c"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['manila_city', 'valenzuela_city', 'taguig_city', 'pasig_city', 'pasay_city', 'paranaque_city', 'muntinlupa_city', 'malabon_city', 'makati_city', 'laspinas_city'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "months = [i for i in range(1,13)]\n",
        "cities_yparam_avg_val_month = {}\n",
        "months \n",
        "for city_fname in CITY_NAME: # or CITY_NAME_2010_2010 || Same value\n",
        "  city_dict_key = city_fname.split(\"_\")[0] + \"_\" + city_fname.split(\"_\")[1]\n",
        "  cities_yparam_avg_val_month[city_dict_key] = {}\n",
        "  \n",
        "  # loop through the climatic factors\n",
        "  for param_name in df_params:\n",
        "    # initialize new empty list every iteration\n",
        "    initial_param_avg_list = []\n",
        "\n",
        "    # loop through the year\n",
        "    for _year in year_range:\n",
        "      # get the average value of the current iterated climatic factor\n",
        "      # add new dictionary key and its value\n",
        "      \n",
        "      for month in months:\n",
        "        param_avg_val_month = np.average(np.array(nt_city_df_dict[city_dict_key].loc[nt_city_df_dict[city_dict_key][\"MO\"] == _year][param_name]))\n",
        "        initial_param_avg_list.append(param_avg_val)\n",
        "        cities_yparam_avg_val_month[city_dict_key][param_name] = np.array(initial_param_avg_list)\n",
        "\n",
        "\n",
        "\n",
        "print(cities_yparam_avg_val_month.keys())"
      ],
      "metadata": {
        "id": "oaUvO1IEpQdO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "paranaque_df = pd.DataFrame(cities_yparam_avg_val[\"paranaque_city\"])\n",
        "valenzuela_df = pd.DataFrame(cities_yparam_avg_val[\"valenzuela_city\"])\n",
        "taguig_df = pd.DataFrame(cities_yparam_avg_val[\"taguig_city\"])\n",
        "makati_df = pd.DataFrame(cities_yparam_avg_val[\"makati_city\"])\n",
        "muntinlupa_df = pd.DataFrame(cities_yparam_avg_val[\"muntinlupa_city\"])\n",
        "manila_df = pd.DataFrame(cities_yparam_avg_val[\"manila_city\"])\n",
        "pasig_df = pd.DataFrame(cities_yparam_avg_val[\"pasig_city\"])\n",
        "las_Pinas_df = pd.DataFrame(cities_yparam_avg_val[\"laspinas_city\"])\n",
        "pasay_df = pd.DataFrame(cities_yparam_avg_val[\"pasay_city\"])\n",
        "malabon_df = pd.DataFrame(cities_yparam_avg_val[\"malabon_city\"])"
      ],
      "metadata": {
        "id": "5dhQ5NN16Hui"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# (long, lat)\n",
        "paranque_coord = [(nt_city_df_dict[\"paranaque_city\"][\"Long\"].iloc[0], nt_city_df_dict[\"paranaque_city\"][\"Lat\"].iloc[0])] * 10\n",
        "valenzuela_coord = [(nt_city_df_dict[\"valenzuela_city\"][\"Long\"].iloc[0], nt_city_df_dict[\"valenzuela_city\"][\"Lat\"].iloc[0])] * 10\n",
        "taguig_coord = [(nt_city_df_dict[\"taguig_city\"][\"Long\"].iloc[0], nt_city_df_dict[\"taguig_city\"][\"Lat\"].iloc[0])] * 10\n",
        "makati_coord = [(nt_city_df_dict[\"makati_city\"][\"Long\"].iloc[0], nt_city_df_dict[\"makati_city\"][\"Lat\"].iloc[0])] * 10\n",
        "muntinlupa_coord = [(nt_city_df_dict[\"muntinlupa_city\"][\"Long\"].iloc[0], nt_city_df_dict[\"muntinlupa_city\"][\"Lat\"].iloc[0])] * 10\n",
        "manila_coord = [(nt_city_df_dict[\"manila_city\"][\"Long\"].iloc[0], nt_city_df_dict[\"manila_city\"][\"Lat\"].iloc[0])] * 10\n",
        "pasig_coord = [(nt_city_df_dict[\"pasig_city\"][\"Long\"].iloc[0], nt_city_df_dict[\"pasig_city\"][\"Lat\"].iloc[0])] * 10\n",
        "pasay_coord = [(nt_city_df_dict[\"pasay_city\"][\"Long\"].iloc[0], nt_city_df_dict[\"pasay_city\"][\"Lat\"].iloc[0])] * 10\n",
        "malabon_coord = [(nt_city_df_dict[\"malabon_city\"][\"Long\"].iloc[0], nt_city_df_dict[\"malabon_city\"][\"Lat\"].iloc[0])] * 10\n",
        "laspinas_coord = [(nt_city_df_dict[\"laspinas_city\"][\"Long\"].iloc[0], nt_city_df_dict[\"laspinas_city\"][\"Lat\"].iloc[0])] * 10\n",
        "\n",
        "\n",
        "g_coords = paranque_coord + valenzuela_coord + taguig_coord + makati_coord + muntinlupa_coord + manila_coord + pasig_coord + pasay_coord + malabon_coord + laspinas_coord\n",
        "cities_df = [\n",
        "    paranaque_df, \n",
        "    valenzuela_df, \n",
        "    taguig_df, \n",
        "    makati_df, \n",
        "    muntinlupa_df, \n",
        "    manila_df, \n",
        "    pasig_df, \n",
        "    pasay_df, \n",
        "    malabon_df, \n",
        "    las_Pinas_df]\n",
        "\n",
        "\n",
        "lpol_data = [\n",
        "    lpol_data_df[\"Paranaque_City\"],\n",
        "    lpol_data_df[\"Manila_City\"],\n",
        "    lpol_data_df[\"Taguig_City\"],\n",
        "    lpol_data_df[\"Pasig_City\"],\n",
        "    lpol_data_df[\"Las Pinas_City\"],\n",
        "    lpol_data_df[\"Muntinlupa_City\"],\n",
        "    lpol_data_df[\"Pasay_City\"],\n",
        "    lpol_data_df[\"Malabon_City\"],\n",
        "    lpol_data_df[\"Valenzuela_City\"],\n",
        "    lpol_data_df[\"Makati_City\"]\n",
        "]\n",
        "\n",
        "NCR_geopckg = get_gpk_fpath(\"grouped_study_area\")\n",
        "NCR_geopckg = gpd.read_file(NCR_geopckg)\n",
        "\n",
        "lpol_df_data = pd.concat(lpol_data)\n",
        "cities_df = pd.concat(cities_df)\n",
        "\n",
        "\n",
        "cities_df[\"LongLat\"] = g_coords\n",
        "cities_df[\"lpol_avg\"] = lpol_df_data"
      ],
      "metadata": {
        "id": "zLkJxa1TnoAo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#cities_df.to_csv(DATASET_DIRECTORY + 'grouped_samnples_pgkg_set.csv')"
      ],
      "metadata": {
        "id": "YVc9_aUsiq9f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1>Multiple Linear Regression</h1>"
      ],
      "metadata": {
        "id": "my5Kc51N0m3A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "manila_x_val = Manila_df\n",
        "manila_y_val = lpol_data_dict[\"Manila_City\"]\n",
        "MANILA_CITY_REG = MMREG_PROCS(manila_x_val, manila_y_val)\n",
        "MANILA_CITY_REG.standard_proc()"
      ],
      "metadata": {
        "id": "ZG5arhaVVG1a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1>Multiscale Linear Regression</h1>"
      ],
      "metadata": {
        "id": "EG6YeE4u0fzc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "g_y = cities_df['lpol_avg'].values.reshape((-1,1)) #T2M\n",
        "g_X = cities_df[['QV2M', \"PS\", \"WS10M\", \"PRECTOTCORR\", \"T2M\"]].values\n",
        "g_coords = list(g_coords)\n",
        "\n",
        "#g_X = (g_X - g_X.mean(axis=0)) / g_X.std(axis=0)\n",
        "#g_y = g_y.reshape((-1,1))\n",
        "#g_y = (g_y - g_y.mean(axis=0)) / g_y.std(axis=0)"
      ],
      "metadata": {
        "id": "hzbu97r5RVrS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "g_X[np.isnan(g_X)] = 0\n",
        "g_y[np.isnan(g_y)] = 0"
      ],
      "metadata": {
        "id": "KbmCsUtcWdZJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gwr_selector = Sel_BW(g_coords, g_y, g_X, kernel = \"gaussian\", fixed = False, spherical=True) \n",
        "gwr_bw = gwr_selector.search(bw_min = 2)\n",
        "gwr_bw"
      ],
      "metadata": {
        "id": "zCysEN81WbsQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gwr_results = GWR(g_coords, g_y, g_X, gwr_bw).fit()"
      ],
      "metadata": {
        "id": "jxZZutFnuJcE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gwr_results.summary()"
      ],
      "metadata": {
        "id": "l8B2qvu2tkFt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gwr_filtered_t = gwr_results.filter_tvals()"
      ],
      "metadata": {
        "id": "94_u-ajc3hIj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def show_plot_by_res_index(res_arg):\n",
        "  fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(15,7))\n",
        "  ax.set_title('GWR Intercept Surface (BW: ' + str(gwr_bw) +')', fontsize=12)\n",
        "\n",
        "  cmap = plt.cm.seismic\n",
        "\n",
        "  gwr_min = res_arg.min()\n",
        "  gwr_max = res_arg.max()\n",
        "  vmin = np.min([gwr_min])\n",
        "  vmax = np.max([gwr_max])\n",
        "\n",
        "  #If all values are negative use the negative half of the colormap\n",
        "  if (vmin < 0) & (vmax < 0):\n",
        "      cmap = truncate_colormap(cmap, 0.0, 0.5)\n",
        "  #If all values are positive use the positive half of the colormap\n",
        "  elif (vmin > 0) & (vmax > 0):\n",
        "      cmap = truncate_colormap(cmap, 0.5, 1.0)\n",
        "  #Otherwise, there are positive and negative values so the colormap so zero is the midpoint\n",
        "  else:\n",
        "      cmap = shift_colormap(cmap, start=0.0, midpoint=1 - vmax/(vmax + abs(vmin)), stop=1.)\n",
        "\n",
        "  sm = plt.cm.ScalarMappable(cmap=cmap, norm=plt.Normalize(vmin=vmin, vmax=vmax))\n",
        "  NCR_geopckg.plot(cmap=sm.cmap, ax=ax, vmin=vmin, vmax=vmax, **{'edgecolor':'black', 'alpha':.65})\n",
        "\n",
        "\n",
        "  fig.tight_layout()    \n",
        "  sm._A = []\n",
        "  cbar = fig.colorbar(sm)\n",
        "  cbar.ax.tick_params(labelsize=12) \n",
        "  ax.get_xaxis().set_visible(False)\n",
        "  ax.get_yaxis().set_visible(False)\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "kROAYNo_zLaS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "show_plot_by_res_index(gwr_results.params[:,0])"
      ],
      "metadata": {
        "id": "2k61yaa6zgvp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "show_plot_by_res_index(gwr_results.params[:,1])"
      ],
      "metadata": {
        "id": "UUHIMJv8zmV6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "show_plot_by_res_index(gwr_results.params[:,2])"
      ],
      "metadata": {
        "id": "XoiJyR1vzvDi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "show_plot_by_res_index(gwr_results.params[:,3])"
      ],
      "metadata": {
        "id": "CYBBKUQjzvbW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "show_plot_by_res_index(gwr_results.params[:,4])"
      ],
      "metadata": {
        "id": "wbop3a_FzwCJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}