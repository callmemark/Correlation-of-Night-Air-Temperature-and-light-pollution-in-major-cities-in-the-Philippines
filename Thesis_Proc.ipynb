{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO1gX+HnrZQcOX3zZrt9UKE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/callmemark/Correlation-of-Night-Air-Temperature-and-light-pollution-in-major-cities-in-the-Philippines/blob/main/Thesis_Proc.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1> Correlation of Night Air Temperature and light pollution in major cities in the Philippines </h1>\n",
        "\n",
        "\n",
        "---\n",
        "</br></br>\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "> Fernandez, Jaron Rix\n",
        "</br>\n",
        "Velmonte, Mark john A.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "RABrvrp2qX4p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1>Preperation 1: Install Libraries</h1>\n",
        "\n",
        "> Install neccesary libraries"
      ],
      "metadata": {
        "id": "Sy9S6BtAqfyX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install GDAL and Geopandas\n",
        "!apt install gdal-bin python-gdal python3-gdal --quiet\n",
        "!apt install python3-rtree --quiet\n",
        "!pip install --upgrade pip --quiet\n",
        "!pip install git+git://github.com/geopandas/geopandas.git --quiet\n",
        "!pip install descartes --quiet\n",
        "!pip install ipywidgets --quiet\n",
        "\n",
        "# Install other libraries\n",
        "!pip install splot --quiet\n",
        "!pip install -U mgwr --quiet\n",
        "\n",
        "#!pip freeze"
      ],
      "metadata": {
        "id": "LdXV1hAsnuyB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1>Preperation 2: Import Libraries</h1>\n",
        "\n",
        "> after installation we procced to import the libraries"
      ],
      "metadata": {
        "id": "YJrBnv2Zqszf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "9oawj62ciWQo"
      },
      "outputs": [],
      "source": [
        "#import libraries\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import geopandas as gpd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib as mpl\n",
        "import libpysal as ps\n",
        "from mgwr.gwr import GWR, MGWR\n",
        "from mgwr.sel_bw import Sel_BW\n",
        "from mgwr.utils import shift_colormap, truncate_colormap\n",
        "from google.colab import drive\n",
        "from os import path, getcwd\n",
        "import itertools\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn import linear_model\n",
        "import statsmodels.api as sm"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1> Preperation 3: Moun Drive </h1>\n",
        "\n",
        "> To access data from google drive, We need to give permission to mount the drive and gain access to folders and files"
      ],
      "metadata": {
        "id": "XiqsCfH7q9Bn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#mount the google drive used\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "2DUnJhipl4Jq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "98116f89-74e2-4a5c-be81-68f30072ce07"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1>Preperation 4: File Reference </h1>\n",
        "\n",
        "> Create a dictionary to use for file path reference and for process automation"
      ],
      "metadata": {
        "id": "_IWQb6eara_5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Helper functions and Classes\n",
        "# from t-19 to t-4\n",
        "\n",
        "\n",
        "def get_gpk_fpath(city_name_arg = str):\n",
        "  try:\n",
        "    return GPKG_DATASET_DIRECTORY + gpkg_files_dict[city_name_arg]\n",
        "  except:\n",
        "    raise Exception(\"error in get_gpk_fpath func | No City in dataset\")\n",
        "    \n",
        "\n",
        "def get_file_path(city_name_arg):\n",
        "  _fstr = DATASET_DIRECTORY + city_name_arg + \".csv\"\n",
        "  return _fstr\n",
        "\n",
        "def read_and_comb_dataset(ds_n1 = str, ds_n2 = str, row_skip = 13):\n",
        "  df_n1 = filter_data(pd.read_csv(ds_n1, skiprows=row_skip))\n",
        "  df_n2 = filter_data(pd.read_csv(ds_n2, skiprows=row_skip))\n",
        "\n",
        "  df_concat = [df_n1, df_n2]\n",
        "  return pd.concat(df_concat)\n",
        "\n",
        "\n",
        "\n",
        "def filter_data(data_frame_arg):\n",
        "  modif_df = data_frame_arg\n",
        "  year_in_data = np.array(data_frame_arg[\"YEAR\"])\n",
        "\n",
        "  if 2011 in year_in_data and 2010 in year_in_data:\n",
        "    modif_df = data_frame_arg.drop(data_frame_arg[data_frame_arg[\"YEAR\"] == 2011].index)\n",
        "    #print(\"Removed 2011\", 2010 in year_in_data)\n",
        "\n",
        "  elif 2010 in year_in_data and 2020 in year_in_data:\n",
        "    modif_df = data_frame_arg.drop(data_frame_arg[data_frame_arg[\"YEAR\"] == 2010].index)\n",
        "    #print(\"Removed 2010\")\n",
        "\n",
        "  elif 2021 in year_in_data and 2020 in year_in_data:\n",
        "    modif_df = data_frame_arg.drop(data_frame_arg[data_frame_arg[\"YEAR\"] == 2021].index)\n",
        "    #print(\"Removed 2021\")\n",
        "  \n",
        "  return modif_df\n",
        "\n",
        "\n",
        "class ProcessMMreg():\n",
        "  def __init__(self, City_Data, y_val_arg = \"T2M\"):\n",
        "    self.city_data = City_Data\n",
        "    self.y_val = y_val_arg\n",
        "\n",
        "    self.city_df = pd.DataFrame(self.city_data)\n",
        "\n",
        "    self.x = self.city_df.drop(columns = self.y_val)\n",
        "    self.y = self.city_df[self.y_val]\n",
        "\n",
        "    self.lr_model = LinearRegression()\n",
        "\n",
        "  def run_standard_proc(self):\n",
        "    self.split_train_test_data()\n",
        "    self.fit_model()\n",
        "    self.predict_data()\n",
        "    self.get_prediction_plot()\n",
        "\n",
        "  def split_train_test_data(self):\n",
        "    self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(self.x, self.y, test_size = 0.3, random_state = 0)\n",
        "    \n",
        "  def fit_model(self):\n",
        "    self.lr_model.fit(self.X_train, self.y_train)\n",
        "  \n",
        "  def predict_data(self):\n",
        "    self.y_pred_train = self.lr_model.predict(self.X_train)\n",
        "\n",
        "  def get_prediction_plot(self):\n",
        "    plt.scatter(self.y_train, self.y_pred_train)\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "Bg4kUtWzpXys"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MMREG_PROCS():\n",
        "  def __init__(self, x_arg, y_arg):\n",
        "    self.x_sample = x_arg\n",
        "    self.y_sample = y_arg\n",
        "\n",
        "\n",
        "  def check_linearity_by_mapping(self, x_axis_arg, y_axis_arg):\n",
        "    plt.scatter(df['interest_rate'], df['index_price'], color='red')\n",
        "    plt.title('Index Price Vs Interest Rate', fontsize=14)\n",
        "    plt.xlabel('Interest Rate', fontsize=14)\n",
        "    plt.ylabel('Index Price', fontsize=14)\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "  \n",
        "\n",
        "  def standard_proc(self, _show_plot_arg = True):\n",
        "    self.scikit_train_proc(show_plot_arg = _show_plot_arg)\n",
        "    self.statmod_proc()\n",
        "\n",
        "\n",
        "  def scikit_train_proc(self, test_size_arg = 0.3, random_state_arg = 0, show_plot_arg = True):\n",
        "    self.lr_model = LinearRegression()\n",
        "    self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(self.x_sample, self.y_sample, test_size = test_size_arg, random_state = random_state_arg)\n",
        "    self.lr_model.fit(self.X_train, self.y_train)\n",
        "    self.y_pred_train = self.lr_model.predict(self.X_train)\n",
        "\n",
        "    if show_plot:\n",
        "      plt.scatter(self.y_train, self.y_pred_train)\n",
        "      plt.show()\n",
        "\n",
        "    return [self.y_train, self.y_pred_train]\n",
        "\n",
        "\n",
        "  def scikit_proc(self):\n",
        "    regr = linear_model.LinearRegression()\n",
        "    fitted_model = regr.fit(x, y)\n",
        "\n",
        "    print(\"Intercept: \", fitted_model.intercept_)\n",
        "    print('Coefficients: ', fitted_model.coef_)\n",
        "\n",
        "    return fitted_model\n",
        "\n",
        "\n",
        "  def statmod_proc(self):\n",
        "    _x = sm.add_constant(self.x_sample)\n",
        " \n",
        "    model = sm.OLS(self.y_sample, _x).fit()\n",
        "    predictions = model.predict(_x) \n",
        "    \n",
        "    reg_ressult = model.summary()\n",
        "    print(reg_ressult)\n",
        "\n",
        "    return reg_ressult\n",
        "\n"
      ],
      "metadata": {
        "id": "E15rZqedKmMD"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "GPKG_DATASET_DIRECTORY = \"/content/drive/My Drive/COLLEGE_THESIS_FOLDER/GPKG_FILES/\"\n",
        "\n",
        "\n",
        "gpkg_files_dict = {\n",
        "    \"Manila_City\" : \"Manila_City.gpkg\",\n",
        "    \"Taguig_City\" : \"Taguig_City.gpkg\",\n",
        "    \"Pasig_City\" : \"Pasig_City.gpkg\",\n",
        "    \"Paranaque_City\" : \"Paranaque_City.gpkg\",\n",
        "    \"Makati_City\" : \"Makati_City.gpkg\",\n",
        "    \"LasPinas_City\" : \"LasPinas_City.gpkg\",\n",
        "    \"Muntinlupa_City\" : \"Muntinlupa_City.gpkg\",\n",
        "    \"Pasay_City\" : \"Pasay_City.gpkg\",\n",
        "    \"Malabon_City\" : \"Malabon_City.gpkg\",\n",
        "    \"Butuan_City\" : \"Butuan_City.gpkg\",\n",
        "    \"grouped_study_area\" : \"grouped_study_area.gpkg\"  \n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "DATASET_DIRECTORY = \"/content/drive/My Drive/COLLEGE_THESIS_FOLDER/DataSet/climactic_factor_dataset_v2/\"\n",
        "\n",
        "CITY_NAME= [\n",
        "    \"manila_city\",\n",
        "    \"valenzuela_city\",\n",
        "    \"taguig_city\",\n",
        "    \"pasig_city\",\n",
        "    \"pasay_city\",\n",
        "    \"paranaque_city\",\n",
        "    \"muntinlupa_city\",\n",
        "    \"malabon_city\",\n",
        "    \"makati_city\",\n",
        "    \"laspinas_city\"\n",
        "]\n",
        "\n",
        "\n",
        "LIGHTPOL_DIRECTORY = \"/content/drive/My Drive/COLLEGE_THESIS_FOLDER/DataSet/Light_pol_data/\"\n",
        "\n",
        "y_ext = [\"2012\", \"2013\", \"2014\", \"2015\", \"2016\", \"2017\", \"2018\", \"2019\", \"2020\", \"2021\"]\n",
        "lpol_cname = [\n",
        "  \"manila_lpol_data_\",\n",
        "  \"taguig_lpol_data_\",\n",
        "  \"pasig_lpol_data_\",\n",
        "  \"paranaque_lpol_data_\",\n",
        "  \"makati_lpol_data_\",\n",
        "  \"laspinas_lpol_data_\",\n",
        "  \"muntinlupa_lpol_data_\",\n",
        "  \"pasay_lpol_data_\",\n",
        "  \"malabon_lpol_data_\",\n",
        "  \"valenzuela_lpol_data_\",\n",
        "]"
      ],
      "metadata": {
        "id": "cyo_qF39lvu_"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dict_keys = ['Manila_City', 'Taguig_City', 'Pasig_City', 'Paranaque_City', 'Makati_City', 'Las Pinas_City', 'Muntinlupa_City', 'Pasay_City', 'Malabon_City', 'Valenzuela_City']\n",
        "lpol_data_dict = {}\n",
        "\n",
        "\n",
        "for _index in range(len(lpol_cname)):\n",
        "  _avg_init_list = []\n",
        "  for _year in y_ext:\n",
        "    fname = lpol_cname[_index] + _year\n",
        "\n",
        "    avg_val = np.average(np.array(pd.read_csv(LIGHTPOL_DIRECTORY + fname + \".csv\", skiprows = 1))) # open csv || skip headder >> convert to numpy >> get avg\n",
        "    _avg_init_list.append(avg_val)\n",
        "\n",
        "  lpol_data_dict[dict_keys[_index]] = _avg_init_list\n",
        "  print(dict_keys[_index], \" Data Process complete\")\n",
        "\n",
        "lpol_data_df = pd.DataFrame(lpol_data_dict)"
      ],
      "metadata": {
        "id": "u_piBR72dTBA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a18ef98a-59e5-49f5-adf7-f5f381a98c65"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Manila_City  Data Process complete\n",
            "Taguig_City  Data Process complete\n",
            "Pasig_City  Data Process complete\n",
            "Paranaque_City  Data Process complete\n",
            "Makati_City  Data Process complete\n",
            "Las Pinas_City  Data Process complete\n",
            "Pasay_City  Data Process complete\n",
            "Malabon_City  Data Process complete\n",
            "Valenzuela_City  Data Process complete\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1>Preperation 5: Helper Function / Classes</h1>\n",
        "\n",
        "> We created functions and classes for process that we know we will repeat \n",
        "<br>\n",
        "> For modularity we adapt object oriented programming paradigm\n"
      ],
      "metadata": {
        "id": "XURlSmJjr3z9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1>Procedure 1: Prepare Data</h1>\n",
        "\n",
        "In this Section we prepare the data by filtering and selecting data that is neccesary to the research"
      ],
      "metadata": {
        "id": "8rC0oguPp2SC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create a empty dictionary\n",
        "nt_city_df_dict = {}\n",
        "\n",
        "# loop through the list\n",
        "for city in CITY_NAME:\n",
        "  dict_key = city\n",
        "  city_df = pd.read_csv(get_file_path(city), skiprows = 13)\n",
        "  \n",
        "  # filter data from t-19 to t-04\n",
        "  print(\"Proc city: \", city)\n",
        "  nightime_data = city_df.loc[(city_df[\"HR\"] <= 4) | (city_df[\"HR\"] >= 19)]\n",
        "\n",
        "  # create new dictinary item and add new data\n",
        "  nt_city_df_dict[dict_key] = nightime_data\n",
        "\n",
        "\n",
        "print(nt_city_df_dict.keys())"
      ],
      "metadata": {
        "id": "Pu1kWyc6pas5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78d5807a-4fde-4e20-bb97-46020051c1c6"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Proc city:  manila_city\n",
            "Proc city:  valenzuela_city\n",
            "Proc city:  taguig_city\n",
            "Proc city:  pasig_city\n",
            "Proc city:  pasay_city\n",
            "Proc city:  paranaque_city\n",
            "Proc city:  muntinlupa_city\n",
            "Proc city:  malabon_city\n",
            "Proc city:  makati_city\n",
            "Proc city:  laspinas_city\n",
            "dict_keys(['manila_city', 'valenzuela_city', 'taguig_city', 'pasig_city', 'pasay_city', 'paranaque_city', 'muntinlupa_city', 'malabon_city', 'makati_city', 'laspinas_city'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# year 2011-2020\n",
        "year_range = [i for i in range(2012, 2022)]\n",
        "# climactic factors\n",
        "df_params = [\"PS\", \"T2M\", \"QV2M\", \"WS10M\", \"PRECTOTCORR\", \"Lat\", \"Long\"]\n",
        "\n",
        "# initialize empty dictionary\n",
        "cities_yparam_avg_val = {}\n",
        "\n",
        "# loop through the cities \n",
        "for city_name in CITY_NAME: # or CITY_NAME_2010_2010 || Same value\n",
        "  city_dict_key = city_name\n",
        "  cities_yparam_avg_val[city_dict_key] = {}\n",
        "  \n",
        "  # loop through the climatic factors\n",
        "  for param_name in df_params:\n",
        "    # initialize new empty list every iteration\n",
        "    initial_param_avg_list = []\n",
        "\n",
        "    # loop through the year\n",
        "    for _year in year_range:\n",
        "      # get the average value of the current iterated climatic factor\n",
        "\n",
        "      tgt_y = nt_city_df_dict[city_dict_key].loc[nt_city_df_dict[city_dict_key][\"YEAR\"] == _year][param_name]\n",
        "      param_avg_val = np.average(np.array(tgt_y))\n",
        "\n",
        "      # appent to empty list\n",
        "      initial_param_avg_list.append(param_avg_val)\n",
        "\n",
        "      # add new dictionary key and its value\n",
        "      cities_yparam_avg_val[city_dict_key][param_name] = np.array(initial_param_avg_list)\n",
        "\n",
        "\n",
        "print(cities_yparam_avg_val.keys())"
      ],
      "metadata": {
        "id": "sSrV2XzfpdVG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d4187ce-f1b4-4463-982a-a0f2571d430c"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['manila_city', 'valenzuela_city', 'taguig_city', 'pasig_city', 'pasay_city', 'paranaque_city', 'muntinlupa_city', 'malabon_city', 'makati_city', 'laspinas_city'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "months = [i for i in range(1,13)]\n",
        "cities_yparam_avg_val_month = {}\n",
        "months \n",
        "for city_fname in CITY_NAME: # or CITY_NAME_2010_2010 || Same value\n",
        "  city_dict_key = city_fname.split(\"_\")[0] + \"_\" + city_fname.split(\"_\")[1]\n",
        "  cities_yparam_avg_val_month[city_dict_key] = {}\n",
        "  \n",
        "  # loop through the climatic factors\n",
        "  for param_name in df_params:\n",
        "    # initialize new empty list every iteration\n",
        "    initial_param_avg_list = []\n",
        "\n",
        "    # loop through the year\n",
        "    for _year in year_range:\n",
        "      # get the average value of the current iterated climatic factor\n",
        "      # add new dictionary key and its value\n",
        "      \n",
        "      for month in months:\n",
        "        param_avg_val_month = np.average(np.array(nt_city_df_dict[city_dict_key].loc[nt_city_df_dict[city_dict_key][\"MO\"] == _year][param_name]))\n",
        "        initial_param_avg_list.append(param_avg_val)\n",
        "        cities_yparam_avg_val_month[city_dict_key][param_name] = np.array(initial_param_avg_list)\n",
        "\n",
        "\n",
        "\n",
        "print(cities_yparam_avg_val_month.keys())"
      ],
      "metadata": {
        "id": "oaUvO1IEpQdO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ff3d7f4-3473-4b4f-ec3f-616169f68261"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/function_base.py:380: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis)\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['manila_city', 'valenzuela_city', 'taguig_city', 'pasig_city', 'pasay_city', 'paranaque_city', 'muntinlupa_city', 'malabon_city', 'makati_city', 'laspinas_city'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1>Multiple Linear Regression</h1>"
      ],
      "metadata": {
        "id": "my5Kc51N0m3A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1>Multiscale Linear Regression</h1>"
      ],
      "metadata": {
        "id": "EG6YeE4u0fzc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Paranaque = pd.DataFrame(cities_yparam_avg_val[\"paranaque_city\"])\n",
        "valenzuela_df = pd.DataFrame(cities_yparam_avg_val[\"valenzuela_city\"])\n",
        "taguig_df = pd.DataFrame(cities_yparam_avg_val[\"taguig_city\"])\n",
        "makati_df = pd.DataFrame(cities_yparam_avg_val[\"makati_city\"])\n",
        "muntinlupa_df = pd.DataFrame(cities_yparam_avg_val[\"muntinlupa_city\"])\n",
        "Manila_df = pd.DataFrame(cities_yparam_avg_val[\"manila_city\"])\n",
        "Pasig_df = pd.DataFrame(cities_yparam_avg_val[\"pasig_city\"])\n",
        "Las_Pinas_df = pd.DataFrame(cities_yparam_avg_val[\"laspinas_city\"])\n",
        "Pasay_df = pd.DataFrame(cities_yparam_avg_val[\"pasay_city\"])\n",
        "Malabon_df = pd.DataFrame(cities_yparam_avg_val[\"malabon_city\"])"
      ],
      "metadata": {
        "id": "5dhQ5NN16Hui"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(nt_city_df_dict[\"pasig_city\"][\"Long\"].iloc[0], nt_city_df_dict[\"pasig_city\"][\"Lat\"].iloc[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tj44m45XMAaS",
        "outputId": "ebb0e71b-37d2-4220-d690-29de738d5058"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(121.0851, 14.5764)"
            ]
          },
          "metadata": {},
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# (long, lat)\n",
        "c1_coord = [(nt_city_df_dict[\"paranaque_city\"][\"Long\"].iloc[0], nt_city_df_dict[\"paranaque_city\"][\"Lat\"].iloc[0])] * 10\n",
        "c2_coord = [(nt_city_df_dict[\"valenzuela_city\"][\"Long\"].iloc[0], nt_city_df_dict[\"valenzuela_city\"][\"Lat\"].iloc[0])] * 10\n",
        "c3_coord = [(nt_city_df_dict[\"taguig_city\"][\"Long\"].iloc[0], nt_city_df_dict[\"taguig_city\"][\"Lat\"].iloc[0])] * 10\n",
        "c4_coord = [(nt_city_df_dict[\"makati_city\"][\"Long\"].iloc[0], nt_city_df_dict[\"makati_city\"][\"Lat\"].iloc[0])] * 10\n",
        "c5_coord = [(nt_city_df_dict[\"muntinlupa_city\"][\"Long\"].iloc[0], nt_city_df_dict[\"muntinlupa_city\"][\"Lat\"].iloc[0])] * 10\n",
        "c6_coord = [(nt_city_df_dict[\"manila_city\"][\"Long\"].iloc[0], nt_city_df_dict[\"manila_city\"][\"Lat\"].iloc[0])] * 10\n",
        "c7_coord = [(nt_city_df_dict[\"pasig_city\"][\"Long\"].iloc[0], nt_city_df_dict[\"pasig_city\"][\"Lat\"].iloc[0])] * 10\n",
        "c8_coord = [(nt_city_df_dict[\"pasay_city\"][\"Long\"].iloc[0], nt_city_df_dict[\"pasay_city\"][\"Lat\"].iloc[0])] * 10\n",
        "c9_coord = [(nt_city_df_dict[\"malabon_city\"][\"Long\"].iloc[0], nt_city_df_dict[\"malabon_city\"][\"Lat\"].iloc[0])] * 10\n",
        "c0_coord = [(nt_city_df_dict[\"laspinas_city\"][\"Long\"].iloc[0], nt_city_df_dict[\"laspinas_city\"][\"Lat\"].iloc[0])] * 10\n",
        "\n",
        "\n",
        "g_coords = c1_coord + c2_coord + c3_coord + c4_coord + c5_coord + c6_coord + c7_coord + c8_coord + c9_coord + c0_coord\n",
        "cities_df = [Paranaque, valenzuela_df, taguig_df, makati_df, muntinlupa_df, Manila_df, Pasig_df, Pasay_df, Malabon_df, Las_Pinas_df]\n",
        "\n",
        "lpol_data = [\n",
        "    lpol_data_df[\"Paranaque_City\"],\n",
        "    lpol_data_df[\"Manila_City\"],\n",
        "    lpol_data_df[\"Taguig_City\"],\n",
        "    lpol_data_df[\"Pasig_City\"],\n",
        "    lpol_data_df[\"Las Pinas_City\"],\n",
        "    lpol_data_df[\"Muntinlupa_City\"],\n",
        "    lpol_data_df[\"Pasay_City\"],\n",
        "    lpol_data_df[\"Malabon_City\"],\n",
        "    lpol_data_df[\"Valenzuela_City\"],\n",
        "    lpol_data_df[\"Makati_City\"]\n",
        "]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "NCR_geopckg = get_gpk_fpath(\"grouped_study_area\")\n",
        "NCR_geopckg = gpd.read_file(NCR_geopckg)\n",
        "\n",
        "lpol_df_data = pd.concat(lpol_data)\n",
        "cities_df = pd.concat(cities_df)\n",
        "\n",
        "\n",
        "cities_df[\"LongLat\"] = g_coords\n",
        "cities_df[\"lpol_avg\"] = lpol_df_data\n"
      ],
      "metadata": {
        "id": "zLkJxa1TnoAo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "g_y = cities_df['lpol_avg'].values.reshape((-1,1)) #T2M\n",
        "g_X = cities_df[['QV2M', \"PS\", \"WS10M\", \"PRECTOTCORR\", \"T2M\"]].values\n",
        "g_coords = list(g_coords)\n",
        "\n",
        "#g_X = (g_X - g_X.mean(axis=0)) / g_X.std(axis=0)\n",
        "#g_y = g_y.reshape((-1,1))\n",
        "#g_y = (g_y - g_y.mean(axis=0)) / g_y.std(axis=0)"
      ],
      "metadata": {
        "id": "hzbu97r5RVrS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "g_X[np.isnan(g_X)] = 0\n",
        "g_y[np.isnan(g_y)] = 0"
      ],
      "metadata": {
        "id": "KbmCsUtcWdZJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cities_df.to_csv(DATASET_DIRECTORY + 'grouped_samnples_pgkg_set.csv')"
      ],
      "metadata": {
        "id": "YVc9_aUsiq9f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gwr_selector = Sel_BW(g_coords, g_y, g_X, kernel = \"gaussian\", fixed = False, spherical=True) \n",
        "gwr_bw = gwr_selector.search(bw_min = 2)\n",
        "gwr_bw"
      ],
      "metadata": {
        "id": "zCysEN81WbsQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gwr_results = GWR(g_coords, g_y, g_X, gwr_bw).fit()"
      ],
      "metadata": {
        "id": "jxZZutFnuJcE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gwr_results.summary()"
      ],
      "metadata": {
        "id": "l8B2qvu2tkFt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gwr_filtered_t = gwr_results.filter_tvals()"
      ],
      "metadata": {
        "id": "94_u-ajc3hIj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def show_plot_by_res_index(res_arg):\n",
        "  fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(15,7))\n",
        "  ax.set_title('GWR Intercept Surface (BW: ' + str(gwr_bw) +')', fontsize=12)\n",
        "\n",
        "  cmap = plt.cm.seismic\n",
        "\n",
        "  gwr_min = res_arg.min()\n",
        "  gwr_max = res_arg.max()\n",
        "  vmin = np.min([gwr_min])\n",
        "  vmax = np.max([gwr_max])\n",
        "\n",
        "  #If all values are negative use the negative half of the colormap\n",
        "  if (vmin < 0) & (vmax < 0):\n",
        "      cmap = truncate_colormap(cmap, 0.0, 0.5)\n",
        "  #If all values are positive use the positive half of the colormap\n",
        "  elif (vmin > 0) & (vmax > 0):\n",
        "      cmap = truncate_colormap(cmap, 0.5, 1.0)\n",
        "  #Otherwise, there are positive and negative values so the colormap so zero is the midpoint\n",
        "  else:\n",
        "      cmap = shift_colormap(cmap, start=0.0, midpoint=1 - vmax/(vmax + abs(vmin)), stop=1.)\n",
        "\n",
        "  sm = plt.cm.ScalarMappable(cmap=cmap, norm=plt.Normalize(vmin=vmin, vmax=vmax))\n",
        "  NCR_geopckg.plot(cmap=sm.cmap, ax=ax, vmin=vmin, vmax=vmax, **{'edgecolor':'black', 'alpha':.65})\n",
        "\n",
        "\n",
        "  fig.tight_layout()    \n",
        "  sm._A = []\n",
        "  cbar = fig.colorbar(sm)\n",
        "  cbar.ax.tick_params(labelsize=12) \n",
        "  ax.get_xaxis().set_visible(False)\n",
        "  ax.get_yaxis().set_visible(False)\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "kROAYNo_zLaS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "show_plot_by_res_index(gwr_results.params[:,0])"
      ],
      "metadata": {
        "id": "2k61yaa6zgvp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "show_plot_by_res_index(gwr_results.params[:,1])"
      ],
      "metadata": {
        "id": "UUHIMJv8zmV6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "show_plot_by_res_index(gwr_results.params[:,2])"
      ],
      "metadata": {
        "id": "XoiJyR1vzvDi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "show_plot_by_res_index(gwr_results.params[:,3])"
      ],
      "metadata": {
        "id": "CYBBKUQjzvbW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "show_plot_by_res_index(gwr_results.params[:,4])"
      ],
      "metadata": {
        "id": "wbop3a_FzwCJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}